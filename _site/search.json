[
  {
    "objectID": "Salary Trends.html",
    "href": "Salary Trends.html",
    "title": "Salary & Compensation Trends in AI vs. Non-AI Careers",
    "section": "",
    "text": "Recent research has highlighted a growing divergence in salary trends between artificial intelligence (AI)-focused careers and more traditional data science roles. Zhu ((2024)) found that professionals specializing in AI-related fields, such as machine learning engineers and AI researchers, consistently command higher salaries than their non-AI counterparts, including data analysts and general data scientists. This difference in compensation reflects the increasing demand for AI expertise as industries integrate automation, deep learning, and predictive analytics into their operations. While AI roles require specialized skills in areas such as neural networks and natural language processing, traditional data science positions often focus more on business intelligence, statistical analysis, and data visualization, which though even that is valuable it does not see the same salary premiums.\nOther studies reinforce this trend, showing how company size and industry specialization further impact salary structures. Chen, Song, and Lam ((2024)) analyzed U.S. salary trends from 2020 to 2023, reporting that salaries in AI-driven roles have shown steady increases, particularly within mid-to-large tech companies investing in AI innovation. In contrast, non-AI data science roles, such as data analysts, have experienced slower growth, and some projections indicate potential stagnation or slight salary declines in 2024. Similarly, Quan and Raheem ((2023)) found that professionals with expertise in AI, cloud computing, and big data technologies earn higher salaries than those with more generalist skills. Their findings suggest that as AI adoption expands across industries, the wage gap between AI and non-AI roles may continue to grow, emphasizing the importance of specialized technical expertise for long-term career advancement in data science."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site aims to cover a profound investigation related to Trends in Salaries and Compensations in AI vs non AI careers"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "The global job market is undergoing a significant transformation due to various factors, including the rapid adoption of artificial intelligence (AI), evolving work models such as remote work, and shifts in industry-specific wage structures. For job seekers, understanding these dynamics is crucial for making informed decisions about career paths, salary expectations, and work environment preferences. This research aims to analyze salary trends for AI and non-AI careers, as well as the impact of remote work, regional differences, and specific industry on salaries.\n\n\n\nAs the economy adapts to AI technologies, many industries are experiencing shifts in job structures and salary scales. This topic is important because job seekers need to be aware of the changing landscape to make career decisions that align with future trends and personal goals. These years, the rise of AI and automation is creating new job roles while displacing others. Moreover, remote work, which played an important role during the pandemic, has become a permanent feature for many industries. However, questions remain about how compensation for remote roles compares to in-office positions and how it varies across regions and industries. Based on typical trends on the job market, this analysis will explore several key findings:\n\nHow do salaries differ across AI vs. non-AI careers?\nWhat regions offer the highest-paying jobs in AI-related and traditional careers?\nAre remote jobs better paying than in-office roles?\nWhat industries saw the biggest wage growth in 2024?"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "The global job market is undergoing a significant transformation due to various factors, including the rapid adoption of artificial intelligence (AI), evolving work models such as remote work, and shifts in industry-specific wage structures. For job seekers, understanding these dynamics is crucial for making informed decisions about career paths, salary expectations, and work environment preferences. This research aims to analyze salary trends for AI and non-AI careers, as well as the impact of remote work, regional differences, and specific industry on salaries."
  },
  {
    "objectID": "index.html#research-rationale",
    "href": "index.html#research-rationale",
    "title": "Job Market Analysis 2024",
    "section": "",
    "text": "As the economy adapts to AI technologies, many industries are experiencing shifts in job structures and salary scales. This topic is important because job seekers need to be aware of the changing landscape to make career decisions that align with future trends and personal goals. These years, the rise of AI and automation is creating new job roles while displacing others. Moreover, remote work, which played an important role during the pandemic, has become a permanent feature for many industries. However, questions remain about how compensation for remote roles compares to in-office positions and how it varies across regions and industries. Based on typical trends on the job market, this analysis will explore several key findings:\n\nHow do salaries differ across AI vs. non-AI careers?\nWhat regions offer the highest-paying jobs in AI-related and traditional careers?\nAre remote jobs better paying than in-office roles?\nWhat industries saw the biggest wage growth in 2024?"
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\n\n\n\nSpecifically, we removed:\n* Older NAICS and SOC codes (e.g., NAICS2, SOC_2).\nThe North American Industry Classification System (NAICS) and Standard Occupational Classification (SOC) systems undergo periodic updates. Retaining only NAICS_2022_6 and SOC_2021_4 ensures we use the most recent classification standards. Moreover, older codes are redundant and may lead to inconsistencies in trend analysis.\n* Tracking data and URLs (e.g., ID, DUPLICATES).\nThese columns related to data collection timestamps, unique identifiers, or internal system references, which do not contribute to meaningful insights about the job market. Similarly, URLs are not necessary for our analysis as they do not provide any additional value or context but add unnecessary complexity to the dataset.\n\n\n\nThere are some reasons for this. Firstly, keeping only the latest industry and occupation classifications ensures our analysis reflects the most recent classification standards and avoid confusion and inconsistencies in classification. Additionally, reducing unnecessary columns speeds up data processing and enhances readability. This is particularly important when working with large datasets, as it minimizes the risk of errors and improves the efficiency of our analysis. Finally, it helps to focus on the most relevant information, allowing for clearer insights and conclusions regarding job market trends.\n\n\n\nBy removing outdated and irrelevant columns, we achieve:\n* More accurate job market trends, focusing on meaningful variables.\n* Easier interpretation without clutter from redundant or technical fields.\n* Faster analysis and visualization, improving overall efficiency.\n\njob_postings = pd.read_csv('lightcast_job_postings.csv')\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_URLS\", \"TITLE\", \"COMPANY\",\n    \"MSA\", \"STATE\", \"COUNTY\", \"CITY\", \"COUNTY_OUTGOING\", \"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\",\n    \"ONET\", \"ONET_2019\", \"CIP2\", \"CIP4\", \"CIP6\", \"MODELED_DURATION\", \"MODELED_EXPIRED\",\n    \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SPECIALIZED_SKILLS\", \"SKILLS\", \"SOFTWARE_SKILLS\",\n    \"LOT_V6_CAREER_AREA\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION\",\n    \"LOT_OCCUPATION_GROUP\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION\", \"LOT_CAREER_AREA\",\n    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\",\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\", \"NAICS_2022_4\", \"NAICS_2022_4_NAME\",\n    \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\",\n    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"SOC_4\",\n    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\", \"SOC_2021_4\"\n]\n\njob_postings.drop(columns = columns_to_drop, inplace = True)\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8, 6))\nmsno.heatmap(job_postings)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n&lt;Figure size 800x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nThe SALARY column has a significant number of missing values. To handle this, we replaced the missing values with the median salary for that specific title or industry. This approach is effective because it minimizes the impact of outliers and provides a more accurate representation of the typical salary for each job title.\n\ntitle_median_salary = job_postings.groupby('TITLE_NAME')['SALARY'].median()\nindustry_median_salary = job_postings.groupby('NAICS_2022_6_NAME')['SALARY'].median()\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: title_median_salary[row['TITLE_NAME']]\n    if pd.isna(row['SALARY']) and row['TITLE_NAME'] in title_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: industry_median_salary[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['SALARY']) and row['NAICS_2022_6_NAME'] in industry_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'].fillna(job_postings[\"SALARY\"].median(), inplace = True)\n\n\n\n\nDealing with columns that have more than 50% missing values is crucial for maintaining the integrity of our dataset. Columns with excessive missing data can introduce bias and reduce the reliability of our analysis. Therefore, we removed any columns that exceed this threshold. This ensures that our dataset remains focused on relevant and reliable information, enhancing the quality of our insights.\n\njob_postings.dropna(thresh = len(job_postings) * 0.5, axis = 1, inplace = True)\n\n\n\n\nCategorical fields, such as TITLE_RAW, were filled with “Unknown” for missing values. This approach allows us to retain the integrity of the dataset without introducing bias from arbitrary values. By labeling missing categorical data as “Unknown”, we can still analyze trends without losing valuable information.\n\njob_postings['TITLE_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['TITLE_CLEAN'].fillna(\"Unknown\", inplace = True)\njob_postings['COMPANY_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_OUTGOING'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_INCOMING'].fillna(\"Unknown\", inplace = True)\n\n\n\n\nFor the EXPIRED variable, we chose to fill the missing values with the maximum date from this column. We assumed that the missing value here is because the post has not expired yet. By using the maximum date, we can effectively handle missing values without introducing bias or skewing the results.\n\njob_postings['POSTED'] = pd.to_datetime(job_postings['POSTED'])\njob_postings['EXPIRED'] = pd.to_datetime(job_postings['EXPIRED'])\n\n\nmax_expired_date = job_postings['EXPIRED'].max()\njob_postings['EXPIRED'] = job_postings['EXPIRED'].fillna(max_expired_date)\n\n\n\n\nFor the MIN_YEARS_EXPERIENCE variable, we chose to fill the missing values with the median MIN_YEARS_EXPERIENCE for a specific title or industry, similar to how we did with the SALARY variable. This can minimize the impact of outliers and provides a more accurate representation of the typical years of experience required for each job title.\n\ntitle_median_exp = job_postings.groupby('TITLE_NAME')['MIN_YEARS_EXPERIENCE'].median()\nindustry_median_exp = job_postings.groupby('NAICS_2022_6_NAME')['MIN_YEARS_EXPERIENCE'].median()\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: title_median_exp[row['TITLE_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['TITLE_NAME'] in title_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: industry_median_exp[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['NAICS_2022_6_NAME'] in industry_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'].fillna(job_postings[\"MIN_YEARS_EXPERIENCE\"].median(), inplace = True)\n\nDURATION variable is also a numerical field, but it has a different approach. We will fill the missing values with the difference between the POSTED and EXPIRED, which calculates the actual time span based on the available dates.\n\ndef impute_duration(cols):\n    posted = cols[0]\n    expired = cols[1]\n    duration = cols[2]\n\n    if pd.isnull(duration):\n        return expired - posted\n    else: \n        return duration\n\n\njob_postings['DURATION'] = job_postings[['POSTED', 'EXPIRED', 'DURATION']].apply(impute_duration, axis = 1)\n\n\n\n\n\n\n\n\n\njob_postings = job_postings.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep = \"first\")"
  },
  {
    "objectID": "data_analysis.html#dropping-unnecessary-columns",
    "href": "data_analysis.html#dropping-unnecessary-columns",
    "title": "Data Analysis",
    "section": "",
    "text": "Specifically, we removed:\n* Older NAICS and SOC codes (e.g., NAICS2, SOC_2).\nThe North American Industry Classification System (NAICS) and Standard Occupational Classification (SOC) systems undergo periodic updates. Retaining only NAICS_2022_6 and SOC_2021_4 ensures we use the most recent classification standards. Moreover, older codes are redundant and may lead to inconsistencies in trend analysis.\n* Tracking data and URLs (e.g., ID, DUPLICATES).\nThese columns related to data collection timestamps, unique identifiers, or internal system references, which do not contribute to meaningful insights about the job market. Similarly, URLs are not necessary for our analysis as they do not provide any additional value or context but add unnecessary complexity to the dataset.\n\n\n\nThere are some reasons for this. Firstly, keeping only the latest industry and occupation classifications ensures our analysis reflects the most recent classification standards and avoid confusion and inconsistencies in classification. Additionally, reducing unnecessary columns speeds up data processing and enhances readability. This is particularly important when working with large datasets, as it minimizes the risk of errors and improves the efficiency of our analysis. Finally, it helps to focus on the most relevant information, allowing for clearer insights and conclusions regarding job market trends.\n\n\n\nBy removing outdated and irrelevant columns, we achieve:\n* More accurate job market trends, focusing on meaningful variables.\n* Easier interpretation without clutter from redundant or technical fields.\n* Faster analysis and visualization, improving overall efficiency.\n\njob_postings = pd.read_csv('lightcast_job_postings.csv')\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_URLS\", \"TITLE\", \"COMPANY\",\n    \"MSA\", \"STATE\", \"COUNTY\", \"CITY\", \"COUNTY_OUTGOING\", \"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\",\n    \"ONET\", \"ONET_2019\", \"CIP2\", \"CIP4\", \"CIP6\", \"MODELED_DURATION\", \"MODELED_EXPIRED\",\n    \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SPECIALIZED_SKILLS\", \"SKILLS\", \"SOFTWARE_SKILLS\",\n    \"LOT_V6_CAREER_AREA\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION\",\n    \"LOT_OCCUPATION_GROUP\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION\", \"LOT_CAREER_AREA\",\n    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\",\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\", \"NAICS_2022_4\", \"NAICS_2022_4_NAME\",\n    \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\",\n    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"SOC_4\",\n    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\", \"SOC_2021_4\"\n]\n\njob_postings.drop(columns = columns_to_drop, inplace = True)"
  },
  {
    "objectID": "data_analysis.html#handling-missing-values",
    "href": "data_analysis.html#handling-missing-values",
    "title": "Data Analysis",
    "section": "",
    "text": "plt.figure(figsize=(8, 6))\nmsno.heatmap(job_postings)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n&lt;Figure size 800x600 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nThe SALARY column has a significant number of missing values. To handle this, we replaced the missing values with the median salary for that specific title or industry. This approach is effective because it minimizes the impact of outliers and provides a more accurate representation of the typical salary for each job title.\n\ntitle_median_salary = job_postings.groupby('TITLE_NAME')['SALARY'].median()\nindustry_median_salary = job_postings.groupby('NAICS_2022_6_NAME')['SALARY'].median()\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: title_median_salary[row['TITLE_NAME']]\n    if pd.isna(row['SALARY']) and row['TITLE_NAME'] in title_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: industry_median_salary[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['SALARY']) and row['NAICS_2022_6_NAME'] in industry_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'].fillna(job_postings[\"SALARY\"].median(), inplace = True)\n\n\n\n\nDealing with columns that have more than 50% missing values is crucial for maintaining the integrity of our dataset. Columns with excessive missing data can introduce bias and reduce the reliability of our analysis. Therefore, we removed any columns that exceed this threshold. This ensures that our dataset remains focused on relevant and reliable information, enhancing the quality of our insights.\n\njob_postings.dropna(thresh = len(job_postings) * 0.5, axis = 1, inplace = True)\n\n\n\n\nCategorical fields, such as TITLE_RAW, were filled with “Unknown” for missing values. This approach allows us to retain the integrity of the dataset without introducing bias from arbitrary values. By labeling missing categorical data as “Unknown”, we can still analyze trends without losing valuable information.\n\njob_postings['TITLE_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['TITLE_CLEAN'].fillna(\"Unknown\", inplace = True)\njob_postings['COMPANY_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_OUTGOING'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_INCOMING'].fillna(\"Unknown\", inplace = True)\n\n\n\n\nFor the EXPIRED variable, we chose to fill the missing values with the maximum date from this column. We assumed that the missing value here is because the post has not expired yet. By using the maximum date, we can effectively handle missing values without introducing bias or skewing the results.\n\njob_postings['POSTED'] = pd.to_datetime(job_postings['POSTED'])\njob_postings['EXPIRED'] = pd.to_datetime(job_postings['EXPIRED'])\n\n\nmax_expired_date = job_postings['EXPIRED'].max()\njob_postings['EXPIRED'] = job_postings['EXPIRED'].fillna(max_expired_date)\n\n\n\n\nFor the MIN_YEARS_EXPERIENCE variable, we chose to fill the missing values with the median MIN_YEARS_EXPERIENCE for a specific title or industry, similar to how we did with the SALARY variable. This can minimize the impact of outliers and provides a more accurate representation of the typical years of experience required for each job title.\n\ntitle_median_exp = job_postings.groupby('TITLE_NAME')['MIN_YEARS_EXPERIENCE'].median()\nindustry_median_exp = job_postings.groupby('NAICS_2022_6_NAME')['MIN_YEARS_EXPERIENCE'].median()\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: title_median_exp[row['TITLE_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['TITLE_NAME'] in title_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: industry_median_exp[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['NAICS_2022_6_NAME'] in industry_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'].fillna(job_postings[\"MIN_YEARS_EXPERIENCE\"].median(), inplace = True)\n\nDURATION variable is also a numerical field, but it has a different approach. We will fill the missing values with the difference between the POSTED and EXPIRED, which calculates the actual time span based on the available dates.\n\ndef impute_duration(cols):\n    posted = cols[0]\n    expired = cols[1]\n    duration = cols[2]\n\n    if pd.isnull(duration):\n        return expired - posted\n    else: \n        return duration\n\n\njob_postings['DURATION'] = job_postings[['POSTED', 'EXPIRED', 'DURATION']].apply(impute_duration, axis = 1)"
  },
  {
    "objectID": "data_analysis.html#removing-duplicate-job-postings",
    "href": "data_analysis.html#removing-duplicate-job-postings",
    "title": "Data Analysis",
    "section": "",
    "text": "job_postings = job_postings.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep = \"first\")"
  },
  {
    "objectID": "data_analysis.html#job-postings-by-industry",
    "href": "data_analysis.html#job-postings-by-industry",
    "title": "Data Analysis",
    "section": "2.1 Job Postings by Industry",
    "text": "2.1 Job Postings by Industry\n\nfig = px.bar(job_postings[\"NAICS_2022_6_NAME\"].value_counts(), title=\"Job Postings by Industry\")\nfig.show()\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nThe bar chart illustrates the distribution of job postings across various industries, with a notably high concentration in the “Unclassified Industry” category. This suggests that a significant portion of job postings may lack detailed industry classification, which could impact sector-specific analysis. Among the classified industries, sectors such as Software Publishing, Real Estate Services, and Semiconductor Manufacturing appear to have the highest job postings, indicating strong demand in these fields."
  },
  {
    "objectID": "data_analysis.html#salary-distribution-by-industry",
    "href": "data_analysis.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "2.2 Salary Distribution by Industry",
    "text": "2.2 Salary Distribution by Industry\n\nfig = px.box(job_postings, x=\"NAICS_2022_6_NAME\", y=\"SALARY\", title=\"Salary Distribution by Industry\")\nfig.update_layout(width=1200, height=1000)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe box plot provides a clearer view of salary distributions across industries, highlighting variations in median salaries and outliers. Most industries exhibit salary concentrations below $200K, with some sectors showing significantly higher outliers above $300K-$500K, suggesting high-paying roles in specialized fields.\nAI-related jobs, typically found in industries such as technology, finance, and advanced manufacturing, often contribute to these high-salary outliers. Roles in machine learning, data science, and artificial intelligence engineering command premium salaries due to their specialized skill requirements, talent scarcity, and high demand across multiple industries. The broader salary spread in AI-intensive fields may also reflect differences in job seniority, from entry-level analysts to highly compensated AI researchers and executives.\nAdditionally, AI-driven industries tend to offer competitive compensation to attract top talent, given the rapid pace of technological advancement and the strategic importance of AI in business growth. The dense clustering of lower salaries in non-AI industries indicates a more constrained range, potentially due to standardized pay structures or lower technical barriers to entry."
  },
  {
    "objectID": "data_analysis.html#remote-vs.-on-site-jobs",
    "href": "data_analysis.html#remote-vs.-on-site-jobs",
    "title": "Data Analysis",
    "section": "2.3 Remote vs. On-Site Jobs",
    "text": "2.3 Remote vs. On-Site Jobs\n\nfig = px.pie(job_postings, names=\"REMOTE_TYPE_NAME\", title=\"Remote vs. On-Site Jobs\")\nfig.show()\n\n                            \n                                            \n\n\n\nfiltered_job_postings = job_postings[job_postings[\"REMOTE_TYPE_NAME\"] != \"[None]\"]\nfig = px.pie(filtered_job_postings, names=\"REMOTE_TYPE_NAME\", title=\"Remote vs. On-Site Jobs (Excluding None)\")\nfig.show()\n\n                            \n                                            \n\n\nThe initial pie chart shows that 78.3% of job postings have no specified remote work type, making it difficult to analyze remote work trends accurately. After filtering out these unspecified postings, the revised pie chart provides a clearer view of the distribution of remote job opportunities. Among classified job postings, 78.4% are fully remote, while 14.4% are hybrid, and 7.29% require on-site presence. This suggests that remote work remains the dominant option among classified job postings, with hybrid and on-site roles making up a smaller but notable portion of the market."
  },
  {
    "objectID": "data_analysis.html#top-20-companies-by-job-postings",
    "href": "data_analysis.html#top-20-companies-by-job-postings",
    "title": "Data Analysis",
    "section": "2.1 Top 20 companies by job postings",
    "text": "2.1 Top 20 companies by job postings\n\nfiltered_companies = job_postings[job_postings[\"COMPANY_NAME\"] != \"Unclassified\"]\n\ntop_companies = filtered_companies[\"COMPANY_NAME\"].value_counts().head(20)\n\nfig = px.bar(\n    x=top_companies.values,\n    y=top_companies.index,\n    orientation='h',\n    title=\"Top 20 Companies by Job Postings (Excluding Unclassified)\",\n    labels={'x': 'Number of Job Postings', 'y': 'Company Name'},\n    text=top_companies.values\n)\n\nfig.update_layout(\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"Company\",\n    yaxis={'categoryorder': 'total ascending'}, \n    height=600, \n    width=900\n)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe visualization of the top 20 companies by job postings (excluding “Unclassified”) highlights key trends in the job market, particularly in the increasing demand for AI-related roles. Many of the companies with the most postings—Deloitte, Accenture, PricewaterhouseCoopers (PwC), Oracle, Infosys, Meta, and CDW—are major players in technology, consulting, and digital transformation, sectors that have been heavily investing in AI, machine learning, and data-driven innovation.\nThe dominance of these companies in job postings suggests that careers in AI and technology-related fields are in high demand. Consulting giants like Deloitte, Accenture, PwC, and KPMG are actively expanding their AI divisions, helping businesses integrate AI into their operations. For instance, Deloitte has launched several AI tools, including chatbots like “DARTbot” for audit professionals and “NavigAite” for document review, to enhance efficiency and client services (Stokes, 2025). Additionally, companies like Meta are pioneers in AI research, focusing on areas such as generative AI, automation, and data science. Even in non-tech sectors, financial and healthcare firms such as Citigroup, Cardinal Health, and Blue Cross Blue Shield are leveraging AI for fraud detection, risk assessment, and personalized healthcare.\nThese trends indicate that pursuing a career in AI-related fields, such as data science, machine learning engineering, and AI research, could provide greater job opportunities and higher earning potential. The strong presence of technology and consulting firms in job postings reflects how AI is becoming a fundamental part of business strategies across industries. While traditional, non-AI careers will continue to exist, the rapid push toward automation and intelligent systems suggests that AI-related skills will be increasingly valuable in both technical and non-technical roles. As industries continue adopting AI, professionals who develop expertise in this area may have a competitive advantage in the evolving job market."
  },
  {
    "objectID": "data_analysis.html#top-5-occupations-by-average-salary",
    "href": "data_analysis.html#top-5-occupations-by-average-salary",
    "title": "Data Analysis",
    "section": "2.3 Top 5 Occupations by Average Salary",
    "text": "2.3 Top 5 Occupations by Average Salary\n\navg_salary_per_occupation = job_postings.groupby(\"LOT_V6_OCCUPATION_NAME\")[\"SALARY\"].mean().reset_index()\n\ntop_occupations = avg_salary_per_occupation.sort_values(by=\"SALARY\", ascending=False).head(5)\n\nfig = px.bar(\n        top_occupations,\n        x=\"SALARY\",\n        y=\"LOT_V6_OCCUPATION_NAME\",\n        orientation='h',\n        title=\"Top 5 Occupations by Average Salary\",\n        labels={\"SALARY\": \"Average Salary ($)\", \"LOT_V6_OCCUPATION_NAME\": \"Occupation\"},\n        text=top_occupations[\"SALARY\"]\n    )\n\nfig.update_layout(\n        xaxis_title=\"Average Salary ($)\",\n        yaxis_title=\"Occupation\",\n        yaxis={\"categoryorder\": \"total ascending\"}, \n        height=700,\n        width=900\n    )\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe salary distribution in the graph clearly shows that the highest-paying occupations are directly tied to artificial intelligence, data analytics, and business intelligence. The top-paying role, “Computer Systems Engineer / Architect,” averages over $156,000, followed by “Business Intelligence Analyst” at $125,000 and other AI-driven roles like “Data Mining Analyst” and “Market Research Analyst,” all exceeding $100,000. These occupations rely heavily on AI, machine learning, and data-driven decision-making, making it clear that mastering AI-related skills is directly linked to higher salaries. The strong earnings for these roles indicate that industries are willing to pay a premium for professionals who can build, interpret, and optimize AI-driven systems.\nIn contrast, traditional non-AI careers, which are not as data or automation-focused, tend to fall outside these top salary brackets. The job market is shifting towards AI dependency, where knowing how to work with artificial intelligence, big data, and automation tools is no longer just an advantage but a necessity for higher-paying opportunities. As industries integrate AI at an increasing pace, professionals who fail to develop AI-related expertise risk stagnating in lower-paying roles, while those who embrace AI technologies position themselves for significantly better financial rewards."
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom collections import Counter\nimport json\nimport ast\n\n\n1 Team-based Skill Dataframe\nWith our chosen IT career path as Business Analysts, we identified our current skills relevant to the role and assessed proficiency levels using a numerical scale from 1 to 5:\n1 = Beginner\n2 = Basic Knowledge\n3 = Intermediate\n4 = Advanced\n5 = Expert\nThe following heatmap visualized our team strengths and gaps.\n\njob_postings = pd.read_csv(\"lightcast_job_postings.csv\", low_memory = False)\n\n\nteam_skills_data = {\n    \"Name\": [\"Furong\", \"Marco\"],\n    \"R\": [3, 3],\n    \"Python\": [3, 4],\n    \"SQL\": [2, 3],\n    \"Microsoft Excel\": [5, 5],\n    \"Data Visulization\": [4, 4],\n    \"Amazon Web Services\": [2, 2],\n    \"Risk Analytics\": [3, 3],\n    \"Data Mining\": [3, 3]\n}\n\ndf_team_skills = pd.DataFrame(team_skills_data)\ndf_team_skills.set_index(\"Name\", inplace = True)\n\n\nplt.figure(figsize = (8, 6))\nheatmap = sns.heatmap(df_team_skills, annot = True, cmap = \"YlGnBu\", \n                    linewidths = 0.5, fmt = \".1f\", vmin = 1, vmax = 5)\n\ncbar = heatmap.collections[0].colorbar\ncbar.set_ticks([1, 2, 3, 4, 5])\ncbar.set_ticklabels(['Beginner', 'Basic', 'Intermediate', 'Advanced', 'Expert'])\n\nplt.title(\"Team Skill Levels Heatmap\", fontsize = 16)\nplt.ylabel(\"Average Proficiency (1-5)\", fontsize = 12)\nplt.xlabel(\"Skills\", fontsize = 12)\nplt.xticks(rotation = 40, ha = 'right')\nplt.yticks(rotation = 0, ha = 'right')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2 Team Skills vs. Industry Requirements\nTo compare our team’s skills to industry requirements, we identified the most in-demand skills from IT job postings. We focused on the industry group Computing Infrastructure Providers, Data Processing, Web Hosting, and Related Services, as it closely aligns with our chosen career path.\nThe bar plot below illustrates the top 10 skills most in demand within IT job postings, providing insights into industry expectations.\n\nit_jobs = job_postings[job_postings['NAICS_2022_6'] == 518210]\n\n\nall_skills = []\n\ndef parse_skills(skills_str):\n    try:\n        if pd.isna(skills_str):\n            return []\n        try:\n            return json.loads(skills_str)\n        except:\n            return ast.literal_eval(skills_str)\n    except:\n        print(f\"Warning: Could not parse skills: {skills_str}\")\n        return []\n\nfor skills_str in it_jobs['SKILLS_NAME'].dropna():\n    skills_list = parse_skills(skills_str)\n    all_skills.extend(skills_list)\n\nskill_counter = Counter(all_skills)\ntop_10_skills = skill_counter.most_common(10)\n\ntop_skills_df = pd.DataFrame(top_10_skills, columns = ['Skill', 'Count'])\n\n\ntotal_postings = len(it_jobs)\ntop_skills_df['Percentage'] = (top_skills_df['Count'] / total_postings * 100).round(1)\ntop_skills_df = top_skills_df.sort_values('Count', ascending = False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(\n    x = 'Count', \n    y = 'Skill', \n    data = top_skills_df,\n    hue = 'Skill',\n    palette = \"Blues_r\"\n)\nplt.title(\"Top 10 Skills Required in IT Job Postings\", fontsize = 16)\nplt.xlabel(\"Number of Job Postings\", fontsize = 12)\nplt.ylabel(\"Skills\", fontsize = 12)\nplt.xlim(0, 500) \n\nfor i, row in enumerate(top_skills_df.itertuples()):\n    plt.text(\n        row.Count + 5, \n        i, \n        f\"{row.Count} ({row.Percentage}%)\",\n        va='center'\n    )\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n3 Team Skills Improvement Plan\nThe bar plot of the top 10 most in-demand skills from IT job postings underscores the significance of core technical skills such as Computer Science (35.8%), Data Analysis (32.4%), SQL (30.2%), and Python (24.9%). These skills highlight the industry’s emphasis on data-driven decision-making and coding expertise as fundamental requirements.\nWhen compared to our team’s current skill set, it is evident that we should prioritize developing knowledge in Data Science and SQL, which are highly demanded by the industry. Furthermore, while our team assessment did not initially account for Communication, the plot shows it as the most sought-after skill in IT job postings. This serves as a crucial reminder of the importance of teamwork, collaboration, and effective interpersonal interactions in IT careers. Technical expertise alone is insufficient; the ability to articulate ideas and communicate solutions is critical.\nThe data also reveals that employers value a combination of technical proficiency, soft skills, and operational knowledge. To address skill gaps within our team, we can adopt a collaborative approach:\n\nKnowledge-sharing and mentorship: Team members skilled in communication can guide others in developing interpersonal abilities, while those with expertise in Python or SQL can lead technical workshops.\n\nSpecialization by strengths: Individuals strong in communication can take on tasks such as presentations and stakeholder engagement, whereas those skilled in technology can focus on back-end technical work.\n\nThis strategy not only bridges skill gaps but also optimizes team collaboration, positioning us as more competitive in the IT job market."
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Salary & Compensation Trends in AI vs. Non-AI Careers",
    "section": "",
    "text": "Recent research has highlighted a growing divergence in salary trends between artificial intelligence (AI)-focused careers and more traditional data science roles. Zhu ((2024)) found that professionals specializing in AI-related fields, such as machine learning engineers and AI researchers, consistently command higher salaries than their non-AI counterparts, including data analysts and general data scientists. This difference in compensation reflects the increasing demand for AI expertise as industries integrate automation, deep learning, and predictive analytics into their operations. While AI roles require specialized skills in areas such as neural networks and natural language processing, traditional data science positions often focus more on business intelligence, statistical analysis, and data visualization, which though even that is valuable it does not see the same salary premiums.\nOther studies reinforce this trend, showing how company size and industry specialization further impact salary structures. Chen, Song, and Lam ((2024)) analyzed U.S. salary trends from 2020 to 2023, reporting that salaries in AI-driven roles have shown steady increases, particularly within mid-to-large tech companies investing in AI innovation. In contrast, non-AI data science roles, such as data analysts, have experienced slower growth, and some projections indicate potential stagnation or slight salary declines in 2024. Similarly, Quan and Raheem ((2023)) found that professionals with expertise in AI, cloud computing, and big data technologies earn higher salaries than those with more generalist skills. Their findings suggest that as AI adoption expands across industries, the wage gap between AI and non-AI roles may continue to grow, emphasizing the importance of specialized technical expertise for long-term career advancement in data science."
  },
  {
    "objectID": "data_cleaning.html",
    "href": "data_cleaning.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\n\n\n\nSpecifically, we removed:\nOlder NAICS and SOC codes (e.g., NAICS2, SOC_2). The North American Industry Classification System (NAICS) and Standard Occupational Classification (SOC) systems undergo periodic updates. Retaining only NAICS_2022_6 and SOC_2021_4 ensures we use the most recent classification standards. Moreover, older codes are redundant and may lead to inconsistencies in trend analysis.\nTracking data and URLs (e.g., ID, DUPLICATES). These columns related to data collection timestamps, unique identifiers, or internal system references, which do not contribute to meaningful insights about the job market. Similarly, URLs are not necessary for our analysis as they do not provide any additional value or context but add unnecessary complexity to the dataset.\n\n\n\nThere are some reasons for this. Firstly, keeping only the latest industry and occupation classifications ensures our analysis reflects the most recent classification standards and avoid confusion and inconsistencies in classification. Additionally, reducing unnecessary columns speeds up data processing and enhances readability. This is particularly important when working with large datasets, as it minimizes the risk of errors and improves the efficiency of our analysis. Finally, it helps to focus on the most relevant information, allowing for clearer insights and conclusions regarding job market trends.\n\n\n\nBy removing outdated and irrelevant columns, we achieve:\n1) More accurate job market trends, focusing on meaningful variables.\n2) Easier interpretation without clutter from redundant or technical fields.\n3) Faster analysis and visualization, improving overall efficiency.\n\njob_postings = pd.read_csv('lightcast_job_postings.csv')\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_URLS\", \"TITLE\", \"COMPANY\",\n    \"MSA\", \"STATE\", \"COUNTY\", \"CITY\", \"COUNTY_OUTGOING\", \"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\",\n    \"ONET\", \"ONET_2019\", \"CIP2\", \"CIP4\", \"CIP6\", \"MODELED_DURATION\", \"MODELED_EXPIRED\",\n    \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SPECIALIZED_SKILLS\", \"SKILLS\", \"SOFTWARE_SKILLS\",\n    \"LOT_V6_CAREER_AREA\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION\",\n    \"LOT_OCCUPATION_GROUP\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION\", \"LOT_CAREER_AREA\",\n    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\",\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\", \"NAICS_2022_4\", \"NAICS_2022_4_NAME\",\n    \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\",\n    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"SOC_4\",\n    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\", \"SOC_2021_4\"\n]\n\njob_postings.drop(columns = columns_to_drop, inplace = True)\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8, 6))\nmsno.heatmap(job_postings)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n&lt;Figure size 768x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nThe SALARY column has a significant number of missing values. To handle this, we replaced the missing values with the median salary for that specific title or industry. This approach is effective because it minimizes the impact of outliers and provides a more accurate representation of the typical salary for each job title.\n\ntitle_median_salary = job_postings.groupby('TITLE_NAME')['SALARY'].median()\nindustry_median_salary = job_postings.groupby('NAICS_2022_6_NAME')['SALARY'].median()\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: title_median_salary[row['TITLE_NAME']]\n    if pd.isna(row['SALARY']) and row['TITLE_NAME'] in title_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: industry_median_salary[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['SALARY']) and row['NAICS_2022_6_NAME'] in industry_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'].fillna(job_postings[\"SALARY\"].median(), inplace = True)\n\n\n\n\nDealing with columns that have more than 50% missing values is crucial for maintaining the integrity of our dataset. Columns with excessive missing data can introduce bias and reduce the reliability of our analysis. Therefore, we removed any columns that exceed this threshold. This ensures that our dataset remains focused on relevant and reliable information, enhancing the quality of our insights.\n\njob_postings.dropna(thresh = len(job_postings) * 0.5, axis = 1, inplace = True)\n\n\n\n\nCategorical fields, such as TITLE_RAW, were filled with “Unknown” for missing values. This approach allows us to retain the integrity of the dataset without introducing bias from arbitrary values. By labeling missing categorical data as “Unknown”, we can still analyze trends without losing valuable information.\n\njob_postings['TITLE_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['TITLE_CLEAN'].fillna(\"Unknown\", inplace = True)\njob_postings['COMPANY_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_OUTGOING'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_INCOMING'].fillna(\"Unknown\", inplace = True)\n\n\n\n\nFor the EXPIRED variable, we chose to fill the missing values with the maximum date from this column. We assumed that the missing value here is because the post has not expired yet. By using the maximum date, we can effectively handle missing values without introducing bias or skewing the results.\n\njob_postings['POSTED'] = pd.to_datetime(job_postings['POSTED'])\njob_postings['EXPIRED'] = pd.to_datetime(job_postings['EXPIRED'])\n\n\nmax_expired_date = job_postings['EXPIRED'].max()\njob_postings['EXPIRED'] = job_postings['EXPIRED'].fillna(max_expired_date)\n\n\n\n\nFor the MIN_YEARS_EXPERIENCE variable, we chose to fill the missing values with the median MIN_YEARS_EXPERIENCE for a specific title or industry, similar to how we did with the SALARY variable. This can minimize the impact of outliers and provides a more accurate representation of the typical years of experience required for each job title.\n\ntitle_median_exp = job_postings.groupby('TITLE_NAME')['MIN_YEARS_EXPERIENCE'].median()\nindustry_median_exp = job_postings.groupby('NAICS_2022_6_NAME')['MIN_YEARS_EXPERIENCE'].median()\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: title_median_exp[row['TITLE_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['TITLE_NAME'] in title_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: industry_median_exp[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['NAICS_2022_6_NAME'] in industry_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'].fillna(job_postings[\"MIN_YEARS_EXPERIENCE\"].median(), inplace = True)\n\nDURATION variable is also a numerical field, but it has a different approach. We will fill the missing values with the difference between the POSTED and EXPIRED, which calculates the actual time span based on the available dates.\n\ndef impute_duration(cols):\n    posted = cols[0]\n    expired = cols[1]\n    duration = cols[2]\n\n    if pd.isnull(duration):\n        return expired - posted\n    else: \n        return duration\n\n\njob_postings['DURATION'] = job_postings[['POSTED', 'EXPIRED', 'DURATION']].apply(impute_duration, axis = 1)\n\n\n\n\n\n\n\n\n\njob_postings = job_postings.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep = \"first\")"
  },
  {
    "objectID": "data_cleaning.html#dropping-unnecessary-columns",
    "href": "data_cleaning.html#dropping-unnecessary-columns",
    "title": "Data Analysis",
    "section": "",
    "text": "Specifically, we removed:\nOlder NAICS and SOC codes (e.g., NAICS2, SOC_2). The North American Industry Classification System (NAICS) and Standard Occupational Classification (SOC) systems undergo periodic updates. Retaining only NAICS_2022_6 and SOC_2021_4 ensures we use the most recent classification standards. Moreover, older codes are redundant and may lead to inconsistencies in trend analysis.\nTracking data and URLs (e.g., ID, DUPLICATES). These columns related to data collection timestamps, unique identifiers, or internal system references, which do not contribute to meaningful insights about the job market. Similarly, URLs are not necessary for our analysis as they do not provide any additional value or context but add unnecessary complexity to the dataset.\n\n\n\nThere are some reasons for this. Firstly, keeping only the latest industry and occupation classifications ensures our analysis reflects the most recent classification standards and avoid confusion and inconsistencies in classification. Additionally, reducing unnecessary columns speeds up data processing and enhances readability. This is particularly important when working with large datasets, as it minimizes the risk of errors and improves the efficiency of our analysis. Finally, it helps to focus on the most relevant information, allowing for clearer insights and conclusions regarding job market trends.\n\n\n\nBy removing outdated and irrelevant columns, we achieve:\n1) More accurate job market trends, focusing on meaningful variables.\n2) Easier interpretation without clutter from redundant or technical fields.\n3) Faster analysis and visualization, improving overall efficiency.\n\njob_postings = pd.read_csv('lightcast_job_postings.csv')\n\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_URLS\", \"TITLE\", \"COMPANY\",\n    \"MSA\", \"STATE\", \"COUNTY\", \"CITY\", \"COUNTY_OUTGOING\", \"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\",\n    \"ONET\", \"ONET_2019\", \"CIP2\", \"CIP4\", \"CIP6\", \"MODELED_DURATION\", \"MODELED_EXPIRED\",\n    \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SPECIALIZED_SKILLS\", \"SKILLS\", \"SOFTWARE_SKILLS\",\n    \"LOT_V6_CAREER_AREA\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION\",\n    \"LOT_OCCUPATION_GROUP\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION\", \"LOT_CAREER_AREA\",\n    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\",\n    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\", \"NAICS_2022_4\", \"NAICS_2022_4_NAME\",\n    \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\",\n    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"SOC_4\",\n    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\", \"SOC_2021_4\"\n]\n\njob_postings.drop(columns = columns_to_drop, inplace = True)"
  },
  {
    "objectID": "data_cleaning.html#handling-missing-values",
    "href": "data_cleaning.html#handling-missing-values",
    "title": "Data Analysis",
    "section": "",
    "text": "plt.figure(figsize=(8, 6))\nmsno.heatmap(job_postings)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n&lt;Figure size 768x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\n\nThe SALARY column has a significant number of missing values. To handle this, we replaced the missing values with the median salary for that specific title or industry. This approach is effective because it minimizes the impact of outliers and provides a more accurate representation of the typical salary for each job title.\n\ntitle_median_salary = job_postings.groupby('TITLE_NAME')['SALARY'].median()\nindustry_median_salary = job_postings.groupby('NAICS_2022_6_NAME')['SALARY'].median()\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: title_median_salary[row['TITLE_NAME']]\n    if pd.isna(row['SALARY']) and row['TITLE_NAME'] in title_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'] = job_postings.apply(\n    lambda row: industry_median_salary[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['SALARY']) and row['NAICS_2022_6_NAME'] in industry_median_salary else row['SALARY'], \n    axis=1\n)\n\n\njob_postings['SALARY'].fillna(job_postings[\"SALARY\"].median(), inplace = True)\n\n\n\n\nDealing with columns that have more than 50% missing values is crucial for maintaining the integrity of our dataset. Columns with excessive missing data can introduce bias and reduce the reliability of our analysis. Therefore, we removed any columns that exceed this threshold. This ensures that our dataset remains focused on relevant and reliable information, enhancing the quality of our insights.\n\njob_postings.dropna(thresh = len(job_postings) * 0.5, axis = 1, inplace = True)\n\n\n\n\nCategorical fields, such as TITLE_RAW, were filled with “Unknown” for missing values. This approach allows us to retain the integrity of the dataset without introducing bias from arbitrary values. By labeling missing categorical data as “Unknown”, we can still analyze trends without losing valuable information.\n\njob_postings['TITLE_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['TITLE_CLEAN'].fillna(\"Unknown\", inplace = True)\njob_postings['COMPANY_RAW'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_OUTGOING'].fillna(\"Unknown\", inplace = True)\njob_postings['MSA_NAME_INCOMING'].fillna(\"Unknown\", inplace = True)\n\n\n\n\nFor the EXPIRED variable, we chose to fill the missing values with the maximum date from this column. We assumed that the missing value here is because the post has not expired yet. By using the maximum date, we can effectively handle missing values without introducing bias or skewing the results.\n\njob_postings['POSTED'] = pd.to_datetime(job_postings['POSTED'])\njob_postings['EXPIRED'] = pd.to_datetime(job_postings['EXPIRED'])\n\n\nmax_expired_date = job_postings['EXPIRED'].max()\njob_postings['EXPIRED'] = job_postings['EXPIRED'].fillna(max_expired_date)\n\n\n\n\nFor the MIN_YEARS_EXPERIENCE variable, we chose to fill the missing values with the median MIN_YEARS_EXPERIENCE for a specific title or industry, similar to how we did with the SALARY variable. This can minimize the impact of outliers and provides a more accurate representation of the typical years of experience required for each job title.\n\ntitle_median_exp = job_postings.groupby('TITLE_NAME')['MIN_YEARS_EXPERIENCE'].median()\nindustry_median_exp = job_postings.groupby('NAICS_2022_6_NAME')['MIN_YEARS_EXPERIENCE'].median()\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: title_median_exp[row['TITLE_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['TITLE_NAME'] in title_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n    lambda row: industry_median_exp[row['NAICS_2022_6_NAME']]\n    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['NAICS_2022_6_NAME'] in industry_median_exp else row['MIN_YEARS_EXPERIENCE'], \n    axis=1\n)\n\n\njob_postings['MIN_YEARS_EXPERIENCE'].fillna(job_postings[\"MIN_YEARS_EXPERIENCE\"].median(), inplace = True)\n\nDURATION variable is also a numerical field, but it has a different approach. We will fill the missing values with the difference between the POSTED and EXPIRED, which calculates the actual time span based on the available dates.\n\ndef impute_duration(cols):\n    posted = cols[0]\n    expired = cols[1]\n    duration = cols[2]\n\n    if pd.isnull(duration):\n        return expired - posted\n    else: \n        return duration\n\n\njob_postings['DURATION'] = job_postings[['POSTED', 'EXPIRED', 'DURATION']].apply(impute_duration, axis = 1)"
  },
  {
    "objectID": "data_cleaning.html#removing-duplicate-job-postings",
    "href": "data_cleaning.html#removing-duplicate-job-postings",
    "title": "Data Analysis",
    "section": "",
    "text": "job_postings = job_postings.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep = \"first\")"
  },
  {
    "objectID": "data_cleaning.html#top-20-companies-by-job-postings",
    "href": "data_cleaning.html#top-20-companies-by-job-postings",
    "title": "Data Analysis",
    "section": "2.1 Top 20 companies by job postings",
    "text": "2.1 Top 20 companies by job postings\n\nfiltered_companies = job_postings[job_postings[\"COMPANY_NAME\"] != \"Unclassified\"]\n\ntop_companies = filtered_companies[\"COMPANY_NAME\"].value_counts().head(20)\n\nfig = px.bar(\n    x=top_companies.values,\n    y=top_companies.index,\n    orientation='h',\n    title=\"Top 20 Companies by Job Postings (Excluding Unclassified)\",\n    labels={'x': 'Number of Job Postings', 'y': 'Company Name'},\n    text=top_companies.values\n)\n\nfig.update_layout(\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"Company\",\n    yaxis={'categoryorder': 'total ascending'}, \n    height=600, \n    width=900\n)\n\nfig.show()\n\n        \n        \n        \n\n\n                            \n                                            \n\n\nThe visualization of the top 20 companies by job postings (excluding “Unclassified”) highlights key trends in the job market, particularly in the increasing demand for AI-related roles. Many of the companies with the most postings—Deloitte, Accenture, PricewaterhouseCoopers (PwC), Oracle, Infosys, Meta, and CDW—are major players in technology, consulting, and digital transformation, sectors that have been heavily investing in AI, machine learning, and data-driven innovation.\nThe dominance of these companies in job postings suggests that careers in AI and technology-related fields are in high demand. Consulting giants like Deloitte, Accenture, PwC, and KPMG are actively expanding their AI divisions, helping businesses integrate AI into their operations. For instance, Deloitte has launched several AI tools, including chatbots like “DARTbot” for audit professionals and “NavigAite” for document review, to enhance efficiency and client services Stokes ((2025)). Additionally, companies like Meta are pioneers in AI research, focusing on areas such as generative AI, automation, and data science. Even in non-tech sectors, financial and healthcare firms such as Citigroup, Cardinal Health, and Blue Cross Blue Shield are leveraging AI for fraud detection, risk assessment, and personalized healthcare.\nThese trends indicate that pursuing a career in AI-related fields, such as data science, machine learning engineering, and AI research, could provide greater job opportunities and higher earning potential. The strong presence of technology and consulting firms in job postings reflects how AI is becoming a fundamental part of business strategies across industries. While traditional, non-AI careers will continue to exist, the rapid push toward automation and intelligent systems suggests that AI-related skills will be increasingly valuable in both technical and non-technical roles. As industries continue adopting AI, professionals who develop expertise in this area may have a competitive advantage in the evolving job market."
  },
  {
    "objectID": "data_cleaning.html#salary-distribution-by-industry",
    "href": "data_cleaning.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "2.2 Salary Distribution by Industry",
    "text": "2.2 Salary Distribution by Industry\n\nfig = px.box(job_postings, x=\"NAICS_2022_6_NAME\", y=\"SALARY\", title=\"Salary Distribution by Industry\")\nfig.update_layout(width=1200, height=1000)\nfig.show()\n\n                            \n                                            \n\n\nThe box plot provides a clearer view of salary distributions across industries, highlighting variations in median salaries and outliers. Most industries exhibit salary concentrations below $200K, with some sectors showing significantly higher outliers above $300K-$500K, suggesting high-paying roles in specialized fields.\nAI-related jobs, typically found in industries such as technology, finance, and advanced manufacturing, often contribute to these high-salary outliers. Roles in machine learning, data science, and artificial intelligence engineering command premium salaries due to their specialized skill requirements, talent scarcity, and high demand across multiple industries. The broader salary spread in AI-intensive fields may also reflect differences in job seniority, from entry-level analysts to highly compensated AI researchers and executives.\nAdditionally, AI-driven industries tend to offer competitive compensation to attract top talent, given the rapid pace of technological advancement and the strategic importance of AI in business growth. The dense clustering of lower salaries in non-AI industries indicates a more constrained range, potentially due to standardized pay structures or lower technical barriers to entry."
  },
  {
    "objectID": "data_cleaning.html#top-5-occupations-by-average-salary",
    "href": "data_cleaning.html#top-5-occupations-by-average-salary",
    "title": "Data Analysis",
    "section": "2.3 Top 5 Occupations by Average Salary",
    "text": "2.3 Top 5 Occupations by Average Salary\n\navg_salary_per_occupation = job_postings.groupby(\"LOT_V6_OCCUPATION_NAME\")[\"SALARY\"].mean().reset_index()\n\ntop_occupations = avg_salary_per_occupation.sort_values(by=\"SALARY\", ascending=False).head(5)\n\nfig = px.bar(\n        top_occupations,\n        x=\"SALARY\",\n        y=\"LOT_V6_OCCUPATION_NAME\",\n        orientation='h',\n        title=\"Top 5 Occupations by Average Salary\",\n        labels={\"SALARY\": \"Average Salary ($)\", \"LOT_V6_OCCUPATION_NAME\": \"Occupation\"},\n        text=top_occupations[\"SALARY\"]\n    )\n\nfig.update_layout(\n        xaxis_title=\"Average Salary ($)\",\n        yaxis_title=\"Occupation\",\n        yaxis={\"categoryorder\": \"total ascending\"}, \n        height=700,\n        width=900\n    )\n\nfig.show()\n\n                            \n                                            \n\n\nThe salary distribution in the graph clearly shows that the highest-paying occupations are directly tied to artificial intelligence, data analytics, and business intelligence. The top-paying role, “Computer Systems Engineer / Architect,” averages over $156,000, followed by “Business Intelligence Analyst” at $125,000 and other AI-driven roles like “Data Mining Analyst” and “Market Research Analyst,” all exceeding $100,000. These occupations rely heavily on AI, machine learning, and data-driven decision-making, making it clear that mastering AI-related skills is directly linked to higher salaries. The strong earnings for these roles indicate that industries are willing to pay a premium for professionals who can build, interpret, and optimize AI-driven systems.\nIn contrast, traditional non-AI careers, which are not as data or automation-focused, tend to fall outside these top salary brackets. The job market is shifting towards AI dependency, where knowing how to work with artificial intelligence, big data, and automation tools is no longer just an advantage but a necessity for higher-paying opportunities. As industries integrate AI at an increasing pace, professionals who fail to develop AI-related expertise risk stagnating in lower-paying roles, while those who embrace AI technologies position themselves for significantly better financial rewards."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\n\n\n\nfiltered_companies = job_postings[job_postings[\"COMPANY_NAME\"] != \"Unclassified\"]\n\ntop_companies = filtered_companies[\"COMPANY_NAME\"].value_counts().head(20)\n\nfig = px.bar(\n    x=top_companies.values,\n    y=top_companies.index,\n    orientation='h',\n    title=\"Top 20 Companies by Job Postings (Excluding Unclassified)\",\n    labels={'x': 'Number of Job Postings', 'y': 'Company Name'},\n    text=top_companies.values\n)\n\nfig.update_layout(\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"Company\",\n    yaxis={'categoryorder': 'total ascending'}, \n    height=600, \n    width=900\n)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe visualization of the top 20 companies by job postings (excluding “Unclassified”) highlights key trends in the job market, particularly in the increasing demand for AI-related roles. Many of the companies with the most postings—Deloitte, Accenture, PricewaterhouseCoopers (PwC), Oracle, Infosys, Meta, and CDW—are major players in technology, consulting, and digital transformation, sectors that have been heavily investing in AI, machine learning, and data-driven innovation.\nThe dominance of these companies in job postings suggests that careers in AI and technology-related fields are in high demand. Consulting giants like Deloitte, Accenture, PwC, and KPMG are actively expanding their AI divisions, helping businesses integrate AI into their operations. For instance, Deloitte has launched several AI tools, including chatbots like “DARTbot” for audit professionals and “NavigAite” for document review, to enhance efficiency and client services (Stokes, 2025). Additionally, companies like Meta are pioneers in AI research, focusing on areas such as generative AI, automation, and data science. Even in non-tech sectors, financial and healthcare firms such as Citigroup, Cardinal Health, and Blue Cross Blue Shield are leveraging AI for fraud detection, risk assessment, and personalized healthcare.\nThese trends indicate that pursuing a career in AI-related fields, such as data science, machine learning engineering, and AI research, could provide greater job opportunities and higher earning potential. The strong presence of technology and consulting firms in job postings reflects how AI is becoming a fundamental part of business strategies across industries. While traditional, non-AI careers will continue to exist, the rapid push toward automation and intelligent systems suggests that AI-related skills will be increasingly valuable in both technical and non-technical roles. As industries continue adopting AI, professionals who develop expertise in this area may have a competitive advantage in the evolving job market.\n\n\n\n\nfig = px.box(job_postings, x=\"NAICS_2022_6_NAME\", y=\"SALARY\", title=\"Salary Distribution by Industry\")\nfig.update_layout(width=1200, height=1000)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe box plot provides a clearer view of salary distributions across industries, highlighting variations in median salaries and outliers. Most industries exhibit salary concentrations below $200K, with some sectors showing significantly higher outliers above $300K-$500K, suggesting high-paying roles in specialized fields.\nAI-related jobs, typically found in industries such as technology, finance, and advanced manufacturing, often contribute to these high-salary outliers. Roles in machine learning, data science, and artificial intelligence engineering command premium salaries due to their specialized skill requirements, talent scarcity, and high demand across multiple industries. The broader salary spread in AI-intensive fields may also reflect differences in job seniority, from entry-level analysts to highly compensated AI researchers and executives.\nAdditionally, AI-driven industries tend to offer competitive compensation to attract top talent, given the rapid pace of technological advancement and the strategic importance of AI in business growth. The dense clustering of lower salaries in non-AI industries indicates a more constrained range, potentially due to standardized pay structures or lower technical barriers to entry.\n\n\n\n\navg_salary_per_occupation = job_postings.groupby(\"LOT_V6_OCCUPATION_NAME\")[\"SALARY\"].mean().reset_index()\n\ntop_occupations = avg_salary_per_occupation.sort_values(by=\"SALARY\", ascending=False).head(5)\n\nfig = px.bar(\n        top_occupations,\n        x=\"SALARY\",\n        y=\"LOT_V6_OCCUPATION_NAME\",\n        orientation='h',\n        title=\"Top 5 Occupations by Average Salary\",\n        labels={\"SALARY\": \"Average Salary ($)\", \"LOT_V6_OCCUPATION_NAME\": \"Occupation\"},\n        text=top_occupations[\"SALARY\"]\n    )\n\nfig.update_layout(\n        xaxis_title=\"Average Salary ($)\",\n        yaxis_title=\"Occupation\",\n        yaxis={\"categoryorder\": \"total ascending\"}, \n        height=700,\n        width=900\n    )\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe salary distribution in the graph clearly shows that the highest-paying occupations are directly tied to artificial intelligence, data analytics, and business intelligence. The top-paying role, “Computer Systems Engineer / Architect,” averages over $156,000, followed by “Business Intelligence Analyst” at $125,000 and other AI-driven roles like “Data Mining Analyst” and “Market Research Analyst,” all exceeding $100,000. These occupations rely heavily on AI, machine learning, and data-driven decision-making, making it clear that mastering AI-related skills is directly linked to higher salaries. The strong earnings for these roles indicate that industries are willing to pay a premium for professionals who can build, interpret, and optimize AI-driven systems.\nIn contrast, traditional non-AI careers, which are not as data or automation-focused, tend to fall outside these top salary brackets. The job market is shifting towards AI dependency, where knowing how to work with artificial intelligence, big data, and automation tools is no longer just an advantage but a necessity for higher-paying opportunities. As industries integrate AI at an increasing pace, professionals who fail to develop AI-related expertise risk stagnating in lower-paying roles, while those who embrace AI technologies position themselves for significantly better financial rewards."
  },
  {
    "objectID": "eda.html#top-20-companies-by-job-postings",
    "href": "eda.html#top-20-companies-by-job-postings",
    "title": "Data Analysis",
    "section": "",
    "text": "filtered_companies = job_postings[job_postings[\"COMPANY_NAME\"] != \"Unclassified\"]\n\ntop_companies = filtered_companies[\"COMPANY_NAME\"].value_counts().head(20)\n\nfig = px.bar(\n    x=top_companies.values,\n    y=top_companies.index,\n    orientation='h',\n    title=\"Top 20 Companies by Job Postings (Excluding Unclassified)\",\n    labels={'x': 'Number of Job Postings', 'y': 'Company Name'},\n    text=top_companies.values\n)\n\nfig.update_layout(\n    xaxis_title=\"Number of Job Postings\",\n    yaxis_title=\"Company\",\n    yaxis={'categoryorder': 'total ascending'}, \n    height=600, \n    width=900\n)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe visualization of the top 20 companies by job postings (excluding “Unclassified”) highlights key trends in the job market, particularly in the increasing demand for AI-related roles. Many of the companies with the most postings—Deloitte, Accenture, PricewaterhouseCoopers (PwC), Oracle, Infosys, Meta, and CDW—are major players in technology, consulting, and digital transformation, sectors that have been heavily investing in AI, machine learning, and data-driven innovation.\nThe dominance of these companies in job postings suggests that careers in AI and technology-related fields are in high demand. Consulting giants like Deloitte, Accenture, PwC, and KPMG are actively expanding their AI divisions, helping businesses integrate AI into their operations. For instance, Deloitte has launched several AI tools, including chatbots like “DARTbot” for audit professionals and “NavigAite” for document review, to enhance efficiency and client services (Stokes, 2025). Additionally, companies like Meta are pioneers in AI research, focusing on areas such as generative AI, automation, and data science. Even in non-tech sectors, financial and healthcare firms such as Citigroup, Cardinal Health, and Blue Cross Blue Shield are leveraging AI for fraud detection, risk assessment, and personalized healthcare.\nThese trends indicate that pursuing a career in AI-related fields, such as data science, machine learning engineering, and AI research, could provide greater job opportunities and higher earning potential. The strong presence of technology and consulting firms in job postings reflects how AI is becoming a fundamental part of business strategies across industries. While traditional, non-AI careers will continue to exist, the rapid push toward automation and intelligent systems suggests that AI-related skills will be increasingly valuable in both technical and non-technical roles. As industries continue adopting AI, professionals who develop expertise in this area may have a competitive advantage in the evolving job market."
  },
  {
    "objectID": "eda.html#salary-distribution-by-industry",
    "href": "eda.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "",
    "text": "fig = px.box(job_postings, x=\"NAICS_2022_6_NAME\", y=\"SALARY\", title=\"Salary Distribution by Industry\")\nfig.update_layout(width=1200, height=1000)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe box plot provides a clearer view of salary distributions across industries, highlighting variations in median salaries and outliers. Most industries exhibit salary concentrations below $200K, with some sectors showing significantly higher outliers above $300K-$500K, suggesting high-paying roles in specialized fields.\nAI-related jobs, typically found in industries such as technology, finance, and advanced manufacturing, often contribute to these high-salary outliers. Roles in machine learning, data science, and artificial intelligence engineering command premium salaries due to their specialized skill requirements, talent scarcity, and high demand across multiple industries. The broader salary spread in AI-intensive fields may also reflect differences in job seniority, from entry-level analysts to highly compensated AI researchers and executives.\nAdditionally, AI-driven industries tend to offer competitive compensation to attract top talent, given the rapid pace of technological advancement and the strategic importance of AI in business growth. The dense clustering of lower salaries in non-AI industries indicates a more constrained range, potentially due to standardized pay structures or lower technical barriers to entry."
  },
  {
    "objectID": "eda.html#top-5-occupations-by-average-salary",
    "href": "eda.html#top-5-occupations-by-average-salary",
    "title": "Data Analysis",
    "section": "",
    "text": "avg_salary_per_occupation = job_postings.groupby(\"LOT_V6_OCCUPATION_NAME\")[\"SALARY\"].mean().reset_index()\n\ntop_occupations = avg_salary_per_occupation.sort_values(by=\"SALARY\", ascending=False).head(5)\n\nfig = px.bar(\n        top_occupations,\n        x=\"SALARY\",\n        y=\"LOT_V6_OCCUPATION_NAME\",\n        orientation='h',\n        title=\"Top 5 Occupations by Average Salary\",\n        labels={\"SALARY\": \"Average Salary ($)\", \"LOT_V6_OCCUPATION_NAME\": \"Occupation\"},\n        text=top_occupations[\"SALARY\"]\n    )\n\nfig.update_layout(\n        xaxis_title=\"Average Salary ($)\",\n        yaxis_title=\"Occupation\",\n        yaxis={\"categoryorder\": \"total ascending\"}, \n        height=700,\n        width=900\n    )\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\n\n\nThe salary distribution in the graph clearly shows that the highest-paying occupations are directly tied to artificial intelligence, data analytics, and business intelligence. The top-paying role, “Computer Systems Engineer / Architect,” averages over $156,000, followed by “Business Intelligence Analyst” at $125,000 and other AI-driven roles like “Data Mining Analyst” and “Market Research Analyst,” all exceeding $100,000. These occupations rely heavily on AI, machine learning, and data-driven decision-making, making it clear that mastering AI-related skills is directly linked to higher salaries. The strong earnings for these roles indicate that industries are willing to pay a premium for professionals who can build, interpret, and optimize AI-driven systems.\nIn contrast, traditional non-AI careers, which are not as data or automation-focused, tend to fall outside these top salary brackets. The job market is shifting towards AI dependency, where knowing how to work with artificial intelligence, big data, and automation tools is no longer just an advantage but a necessity for higher-paying opportunities. As industries integrate AI at an increasing pace, professionals who fail to develop AI-related expertise risk stagnating in lower-paying roles, while those who embrace AI technologies position themselves for significantly better financial rewards."
  }
]