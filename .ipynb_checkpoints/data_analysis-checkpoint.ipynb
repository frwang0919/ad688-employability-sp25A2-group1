{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Analysis\"\n",
    "subtitle: \"Comprehensive Data Cleaning & Exploratory Analysis of Job Market Trends\"\n",
    "author:\n",
    "  - name: Furong Wang\n",
    "    affiliations:\n",
    "      - id: bu\n",
    "        name: Boston University\n",
    "        city: Boston\n",
    "        state: MA\n",
    "  - name: Marco Perez Garcia\n",
    "    affiliations:\n",
    "      - ref: bu\n",
    "bibliography: references.bib\n",
    "csl: csl/econometrica.csl\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    number-sections: true\n",
    "    df-print: paged\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning & Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmissingno\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmsno\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting missingno\n",
      "  Downloading missingno-0.5.2-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from missingno) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.11/site-packages (from missingno) (3.8.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from missingno) (1.11.4)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.11/site-packages (from missingno) (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib->missingno) (2.8.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn->missingno) (2.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn->missingno) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn->missingno) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->missingno) (1.16.0)\n",
      "Downloading missingno-0.5.2-py3-none-any.whl (8.7 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To simplify our job market analysis, we need to drop columns that are either unnecessary, duplicated, or outdated. \n",
    "Specifically, we will remove:  \n",
    "**1. Older NAICS and SOC codes (e.g., `NAICS2`, `SOC_2`).**\n",
    "The North American Industry Classification System (NAICS) and Standard Occupational Classification (SOC) systems undergo periodic updates. Retaining only `NAICS_2022_6` and `SOC_2021_4` ensures we use the most recent classification standards. Moreover, older codes are redundant and may lead to inconsistencies in trend analysis.  \n",
    "**2. Tracking data and URLs (e.g., `ID`, `DUPLICATES`).**\n",
    "These columns related to data collection timestamps, unique identifiers, or internal system references, which do not contribute to meaningful insights about the job market. Similarly, URLs are not necessary for our analysis as they do not provide any additional value or context but add unnecessary complexity to the dataset.\n",
    "\n",
    "### Why removing multiple versions of NAICS/SOC codes?\n",
    "There are some reasons for this. Firstly, keeping only the latest industry and occupation classifications ensures our analysis reflects the most recent classification standards and avoid confusion and inconsistencies in classification. Additionally, reducing unnecessary columns speeds up data processing and enhances readability. This is particularly important when working with large datasets, as it minimizes the risk of errors and improves the efficiency of our analysis. Finally, it helps to focus on the most relevant information, allowing for clearer insights and conclusions regarding job market trends.\n",
    "\n",
    "### Impact on Analysis:\n",
    "By removing outdated and irrelevant columns, we achieve:\n",
    "- More accurate job market trends, focusing on meaningful variables.\n",
    "- Easier interpretation without clutter from redundant or technical fields.\n",
    "- Faster analysis and visualization, improving overall efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings = pd.read_csv('lightcast_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\", \"ACTIVE_URLS\", \"TITLE\", \"COMPANY\",\n",
    "    \"MSA\", \"STATE\", \"COUNTY\", \"CITY\", \"COUNTY_OUTGOING\", \"COUNTY_INCOMING\", \"MSA_OUTGOING\", \"MSA_INCOMING\",\n",
    "    \"ONET\", \"ONET_2019\", \"CIP2\", \"CIP4\", \"CIP6\", \"MODELED_DURATION\", \"MODELED_EXPIRED\",\n",
    "    \"CERTIFICATIONS\", \"COMMON_SKILLS\", \"SPECIALIZED_SKILLS\", \"SKILLS\", \"SOFTWARE_SKILLS\",\n",
    "    \"LOT_V6_CAREER_AREA\", \"LOT_V6_OCCUPATION_GROUP\", \"LOT_V6_OCCUPATION\", \"LOT_V6_SPECIALIZED_OCCUPATION\",\n",
    "    \"LOT_OCCUPATION_GROUP\", \"LOT_SPECIALIZED_OCCUPATION\", \"LOT_OCCUPATION\", \"LOT_CAREER_AREA\",\n",
    "    \"NAICS2\", \"NAICS2_NAME\", \"NAICS3\", \"NAICS3_NAME\", \"NAICS4\", \"NAICS4_NAME\", \"NAICS5\", \"NAICS5_NAME\", \"NAICS6\",\n",
    "    \"NAICS_2022_2\", \"NAICS_2022_2_NAME\", \"NAICS_2022_3\", \"NAICS_2022_3_NAME\", \"NAICS_2022_4\", \"NAICS_2022_4_NAME\",\n",
    "    \"NAICS_2022_5\", \"NAICS_2022_5_NAME\", \"NAICS_2022_6\",\n",
    "    \"SOC_2\", \"SOC_2_NAME\", \"SOC_3\", \"SOC_3_NAME\", \"SOC_5\", \"SOC_5_NAME\", \"SOC_4\",\n",
    "    \"SOC_2021_2\", \"SOC_2021_2_NAME\", \"SOC_2021_3\", \"SOC_2021_3_NAME\", \"SOC_2021_5\", \"SOC_2021_5_NAME\", \"SOC_2021_4\"\n",
    "]\n",
    "\n",
    "job_postings.drop(columns = columns_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "### We used different strategies for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(job_postings)\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with the Salary Column\n",
    "The `SALARY` column has a significant number of missing values. To handle this, we replaced the missing values with the median salary for that specific title or industry. This approach is effective because it minimizes the impact of outliers and provides a more accurate representation of the typical salary for each job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_median_salary = job_postings.groupby('TITLE_NAME')['SALARY'].median()\n",
    "industry_median_salary = job_postings.groupby('NAICS_2022_6_NAME')['SALARY'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['SALARY'] = job_postings.apply(\n",
    "    lambda row: title_median_salary[row['TITLE_NAME']]\n",
    "    if pd.isna(row['SALARY']) and row['TITLE_NAME'] in title_median_salary else row['SALARY'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['SALARY'] = job_postings.apply(\n",
    "    lambda row: industry_median_salary[row['NAICS_2022_6_NAME']]\n",
    "    if pd.isna(row['SALARY']) and row['NAICS_2022_6_NAME'] in industry_median_salary else row['SALARY'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['SALARY'].fillna(job_postings[\"SALARY\"].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Columns with >50% missing values\n",
    "Dealing with columns that have more than 50% missing values is crucial for maintaining the integrity of our dataset. Columns with excessive missing data can introduce bias and reduce the reliability of our analysis. Therefore, we removed any columns that exceed this threshold. This ensures that our dataset remains focused on relevant and reliable information, enhancing the quality of our insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings.dropna(thresh = len(job_postings) * 0.5, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Categorical fields\n",
    "Categorical fields, such as `TITLE_RAW`, were filled with \"Unknown\" for missing values. This approach allows us to retain the integrity of the dataset without introducing bias from arbitrary values. By labeling missing categorical data as \"Unknown\", we can still analyze trends without losing valuable information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['TITLE_RAW'].fillna(\"Unknown\", inplace = True)\n",
    "job_postings['TITLE_CLEAN'].fillna(\"Unknown\", inplace = True)\n",
    "job_postings['COMPANY_RAW'].fillna(\"Unknown\", inplace = True)\n",
    "job_postings['MSA_NAME'].fillna(\"Unknown\", inplace = True)\n",
    "job_postings['MSA_NAME_OUTGOING'].fillna(\"Unknown\", inplace = True)\n",
    "job_postings['MSA_NAME_INCOMING'].fillna(\"Unknown\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Datetime fields\n",
    "For the `EXPIRED` variable, we chose to fill the missing values with the maximum date from this column. We assumed that the missing value here is because the post has not expired yet. By using the maximum date, we can effectively handle missing values without introducing bias or skewing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['POSTED'] = pd.to_datetime(job_postings['POSTED'])\n",
    "job_postings['EXPIRED'] = pd.to_datetime(job_postings['EXPIRED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_expired_date = job_postings['EXPIRED'].max()\n",
    "job_postings['EXPIRED'] = job_postings['EXPIRED'].fillna(max_expired_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Numerical fields\n",
    "For the `MIN_YEARS_EXPERIENCE` variable, we chose to fill the missing values with the median `MIN_YEARS_EXPERIENCE` for a specific title or industry, similar to how we did with the `SALARY` variable. This can minimize the impact of outliers and provides a more accurate representation of the typical years of experience required for each job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_median_exp = job_postings.groupby('TITLE_NAME')['MIN_YEARS_EXPERIENCE'].median()\n",
    "industry_median_exp = job_postings.groupby('NAICS_2022_6_NAME')['MIN_YEARS_EXPERIENCE'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n",
    "    lambda row: title_median_exp[row['TITLE_NAME']]\n",
    "    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['TITLE_NAME'] in title_median_exp else row['MIN_YEARS_EXPERIENCE'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['MIN_YEARS_EXPERIENCE'] = job_postings.apply(\n",
    "    lambda row: industry_median_exp[row['NAICS_2022_6_NAME']]\n",
    "    if pd.isna(row['MIN_YEARS_EXPERIENCE']) and row['NAICS_2022_6_NAME'] in industry_median_exp else row['MIN_YEARS_EXPERIENCE'], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['MIN_YEARS_EXPERIENCE'].fillna(job_postings[\"MIN_YEARS_EXPERIENCE\"].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DURATION` variable is also a numerical field, but it has a different approach. We will fill the missing values with the difference between the `POSTED` and `EXPIRED`, which calculates the actual time span based on the available dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_duration(cols):\n",
    "    posted = cols[0]\n",
    "    expired = cols[1]\n",
    "    duration = cols[2]\n",
    "\n",
    "    if pd.isnull(duration):\n",
    "        return expired - posted\n",
    "    else: \n",
    "        return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings['DURATION'] = job_postings[['POSTED', 'EXPIRED', 'DURATION']].apply(impute_duration, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Job Postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To ensure each job is counted only once, we removed duplicates based on job title, company, location, and posting date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings = job_postings.drop_duplicates(subset=[\"TITLE_NAME\", \"COMPANY_NAME\", \"LOCATION\", \"POSTED\"], keep = \"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Postings by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df[\"Industry\"].value_counts(), title=\"Job Postings by Industry\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Distribution by Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote vs. On-Site Jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
